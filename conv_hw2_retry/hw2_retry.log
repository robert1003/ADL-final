Namespace(batch_size=4, cuda=2, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=20, hw2_QA_bert='bert.pth', kernel_size=7, learning_rate=3e-05, log_name='hw2_retry.log', merge_type=0, model_name='hw2_retry.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=2.0, round=2000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/20: training loss = 0.47029, dev loss = 0.23217, dev f1 score = 0.92865, Time 10m 26s (- 198m 22s)
Update best f1: 0.00000 -> 0.92865, thres 0.20, saving model to f1_hw2_retry.pth
Update best loss: 1000000000.00000 -> 0.23217, saving model to loss_hw2_retry.pth
Epoch 2/20: training loss = 0.23847, dev loss = 0.22861, dev f1 score = 0.92517, Time 21m 15s (- 191m 18s)
Update best loss: 0.23217 -> 0.22861, saving model to loss_hw2_retry.pth
Epoch 3/20: training loss = 0.20076, dev loss = 0.20359, dev f1 score = 0.93683, Time 31m 53s (- 180m 44s)
Update best f1: 0.92865 -> 0.93683, thres 0.20, saving model to f1_hw2_retry.pth
Update best loss: 0.22861 -> 0.20359, saving model to loss_hw2_retry.pth
Epoch 4/20: training loss = 0.20003, dev loss = 0.22915, dev f1 score = 0.93087, Time 42m 43s (- 170m 53s)
Epoch 5/20: training loss = 0.16484, dev loss = 0.21406, dev f1 score = 0.93610, Time 53m 9s (- 159m 29s)
Epoch 6/20: training loss = 0.16642, dev loss = 0.17768, dev f1 score = 0.93523, Time 63m 37s (- 148m 26s)
Update best loss: 0.20359 -> 0.17768, saving model to loss_hw2_retry.pth
Epoch 7/20: training loss = 0.14293, dev loss = 0.21574, dev f1 score = 0.92973, Time 74m 20s (- 138m 3s)
Epoch 8/20: training loss = 0.14443, dev loss = 0.20624, dev f1 score = 0.93687, Time 84m 47s (- 127m 10s)
Update best f1: 0.93683 -> 0.93687, thres 0.20, saving model to f1_hw2_retry.pth
Epoch 9/20: training loss = 0.15230, dev loss = 0.17028, dev f1 score = 0.93564, Time 95m 27s (- 116m 39s)
Update best loss: 0.17768 -> 0.17028, saving model to loss_hw2_retry.pth
Epoch 10/20: training loss = 0.14223, dev loss = 0.19205, dev f1 score = 0.92972, Time 106m 5s (- 106m 5s)
Epoch 11/20: training loss = 0.12714, dev loss = 0.22134, dev f1 score = 0.93866, Time 116m 34s (- 95m 22s)
Update best f1: 0.93687 -> 0.93866, thres 0.20, saving model to f1_hw2_retry.pth
Epoch 12/20: training loss = 0.11793, dev loss = 0.23180, dev f1 score = 0.93532, Time 127m 15s (- 84m 50s)
Epoch 13/20: training loss = 0.10312, dev loss = 0.19986, dev f1 score = 0.94039, Time 137m 43s (- 74m 9s)
Update best f1: 0.93866 -> 0.94039, thres 0.20, saving model to f1_hw2_retry.pth
Epoch 14/20: training loss = 0.11434, dev loss = 0.24382, dev f1 score = 0.93020, Time 148m 22s (- 63m 35s)
Epoch 15/20: training loss = 0.09743, dev loss = 0.26334, dev f1 score = 0.93207, Time 158m 51s (- 52m 57s)
Epoch 16/20: training loss = 0.10177, dev loss = 0.21744, dev f1 score = 0.93584, Time 169m 20s (- 42m 20s)
Epoch 17/20: training loss = 0.09688, dev loss = 0.26528, dev f1 score = 0.92905, Time 179m 45s (- 31m 43s)
Epoch 18/20: training loss = 0.10600, dev loss = 0.20774, dev f1 score = 0.93923, Time 190m 12s (- 21m 8s)
Epoch 19/20: training loss = 0.09315, dev loss = 0.21829, dev f1 score = 0.93336, Time 200m 37s (- 10m 33s)
Epoch 20/20: training loss = 0.08496, dev loss = 0.22434, dev f1 score = 0.93132, Time 211m 5s (- 0m 0s)
Best dev f1: 0.94039 Best dev loss: 0.17028
