Namespace(batch_size=4, cuda=1, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=50, hw2_QA_bert='../bert.pth', kernel_size=7, learning_rate=5e-06, log_name='parent_sampler_higher_ratio.log', merge_type=0, model_name='parent_sampler_higher_ratio.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=6.0, round=2000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/50: training loss = 0.38901, dev loss = 0.07801, dev f1 score = 0.94141, Time 18m 39s (- 914m 39s)
Update best f1: 0.00000 -> 0.94141, thres 0.10, saving model to f1_parent_sampler_higher_ratio.pth
Update best loss: 1000000000.00000 -> 0.07801, saving model to loss_parent_sampler_higher_ratio.pth
Epoch 2/50: training loss = 0.12027, dev loss = 0.06013, dev f1 score = 0.95469, Time 37m 8s (- 891m 28s)
Update best f1: 0.94141 -> 0.95469, thres 0.10, saving model to f1_parent_sampler_higher_ratio.pth
Update best loss: 0.07801 -> 0.06013, saving model to loss_parent_sampler_higher_ratio.pth
Epoch 3/50: training loss = 0.09554, dev loss = 0.07857, dev f1 score = 0.95645, Time 55m 42s (- 872m 42s)
Update best f1: 0.95469 -> 0.95645, thres 0.10, saving model to f1_parent_sampler_higher_ratio.pth
Epoch 4/50: training loss = 0.07849, dev loss = 0.04124, dev f1 score = 0.95854, Time 73m 55s (- 850m 3s)
Update best f1: 0.95645 -> 0.95854, thres 0.30, saving model to f1_parent_sampler_higher_ratio.pth
Update best loss: 0.06013 -> 0.04124, saving model to loss_parent_sampler_higher_ratio.pth
Epoch 5/50: training loss = 0.07191, dev loss = 0.07594, dev f1 score = 0.95620, Time 92m 4s (- 828m 36s)
Epoch 6/50: training loss = 0.07512, dev loss = 0.04671, dev f1 score = 0.95768, Time 110m 19s (- 809m 5s)
Epoch 7/50: training loss = 0.06228, dev loss = 0.04876, dev f1 score = 0.95980, Time 128m 39s (- 790m 18s)
Update best f1: 0.95854 -> 0.95980, thres 0.30, saving model to f1_parent_sampler_higher_ratio.pth
Epoch 8/50: training loss = 0.06015, dev loss = 0.05465, dev f1 score = 0.95789, Time 146m 47s (- 770m 39s)
Epoch 9/50: training loss = 0.06316, dev loss = 0.04272, dev f1 score = 0.95950, Time 165m 6s (- 752m 8s)
Epoch 10/50: training loss = 0.05263, dev loss = 0.04184, dev f1 score = 0.96338, Time 183m 23s (- 733m 32s)
Update best f1: 0.95980 -> 0.96338, thres 0.40, saving model to f1_parent_sampler_higher_ratio.pth
Epoch 11/50: training loss = 0.05709, dev loss = 0.05980, dev f1 score = 0.96017, Time 201m 44s (- 715m 16s)
Epoch 12/50: training loss = 0.05208, dev loss = 0.05160, dev f1 score = 0.96064, Time 219m 55s (- 696m 26s)
Epoch 13/50: training loss = 0.04663, dev loss = 0.05458, dev f1 score = 0.96216, Time 238m 14s (- 678m 4s)
Epoch 14/50: training loss = 0.04120, dev loss = 0.05570, dev f1 score = 0.96430, Time 256m 24s (- 659m 19s)
Update best f1: 0.96338 -> 0.96430, thres 0.10, saving model to f1_parent_sampler_higher_ratio.pth
Epoch 15/50: training loss = 0.04320, dev loss = 0.04709, dev f1 score = 0.96143, Time 274m 43s (- 641m 1s)
Epoch 16/50: training loss = 0.04461, dev loss = 0.04978, dev f1 score = 0.95882, Time 292m 58s (- 622m 34s)
Epoch 17/50: training loss = 0.04240, dev loss = 0.05239, dev f1 score = 0.95851, Time 311m 33s (- 604m 46s)
Epoch 18/50: training loss = 0.03829, dev loss = 0.04751, dev f1 score = 0.96454, Time 330m 1s (- 586m 42s)
Update best f1: 0.96430 -> 0.96454, thres 0.40, saving model to f1_parent_sampler_higher_ratio.pth
Epoch 19/50: training loss = 0.04120, dev loss = 0.05888, dev f1 score = 0.96112, Time 348m 22s (- 568m 24s)
Epoch 20/50: training loss = 0.04482, dev loss = 0.05524, dev f1 score = 0.95896, Time 366m 36s (- 549m 54s)
Epoch 21/50: training loss = 0.03530, dev loss = 0.04360, dev f1 score = 0.96197, Time 384m 56s (- 531m 35s)
Epoch 22/50: training loss = 0.04156, dev loss = 0.04590, dev f1 score = 0.95960, Time 403m 12s (- 513m 10s)
Epoch 23/50: training loss = 0.03736, dev loss = 0.05526, dev f1 score = 0.95970, Time 421m 37s (- 494m 57s)
Epoch 24/50: training loss = 0.03937, dev loss = 0.04418, dev f1 score = 0.96210, Time 439m 51s (- 476m 30s)
Epoch 25/50: training loss = 0.03906, dev loss = 0.04236, dev f1 score = 0.96289, Time 458m 1s (- 458m 1s)
Epoch 26/50: training loss = 0.03638, dev loss = 0.05154, dev f1 score = 0.95902, Time 476m 11s (- 439m 33s)
Epoch 27/50: training loss = 0.03125, dev loss = 0.05506, dev f1 score = 0.96239, Time 494m 9s (- 420m 56s)
Epoch 28/50: training loss = 0.03411, dev loss = 0.04960, dev f1 score = 0.96093, Time 512m 31s (- 402m 42s)
Epoch 29/50: training loss = 0.04108, dev loss = 0.04253, dev f1 score = 0.96270, Time 530m 54s (- 384m 27s)
Epoch 30/50: training loss = 0.03463, dev loss = 0.04990, dev f1 score = 0.96176, Time 549m 7s (- 366m 5s)
Epoch 31/50: training loss = 0.03064, dev loss = 0.04991, dev f1 score = 0.96041, Time 567m 34s (- 347m 51s)
Epoch 32/50: training loss = 0.03388, dev loss = 0.04977, dev f1 score = 0.96065, Time 585m 53s (- 329m 33s)
Epoch 33/50: training loss = 0.03062, dev loss = 0.04706, dev f1 score = 0.96260, Time 604m 19s (- 311m 19s)
Epoch 34/50: training loss = 0.03393, dev loss = 0.04830, dev f1 score = 0.96288, Time 622m 30s (- 292m 56s)
Epoch 35/50: training loss = 0.03423, dev loss = 0.04705, dev f1 score = 0.96040, Time 640m 46s (- 274m 37s)
Epoch 36/50: training loss = 0.03146, dev loss = 0.05026, dev f1 score = 0.96333, Time 658m 58s (- 256m 15s)
Epoch 37/50: training loss = 0.03511, dev loss = 0.04977, dev f1 score = 0.96315, Time 677m 13s (- 237m 56s)
