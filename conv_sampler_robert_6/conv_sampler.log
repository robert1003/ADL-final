Namespace(cuda=1, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=100, kernel_size=7, learning_rate=5e-06, log_name='conv_sampler.log', model_name='conv_sampler.pth', pretrained_model='bert-base-multilingual-cased', ratio=4.0, round=2000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/100: training loss = 1.19908, dev loss = 0.39539, dev f1 score = 0.91510, Time 10m 21s (- 1025m 49s)
Update best f1: 0.00000 -> 0.91510, saving model to conv_sampler.pth
Epoch 2/100: training loss = 0.49072, dev loss = 0.28221, dev f1 score = 0.92077, Time 21m 14s (- 1041m 6s)
Update best f1: 0.91510 -> 0.92077, saving model to conv_sampler.pth
Epoch 3/100: training loss = 0.41212, dev loss = 0.29243, dev f1 score = 0.92233, Time 32m 13s (- 1041m 51s)
Update best f1: 0.92077 -> 0.92233, saving model to conv_sampler.pth
Epoch 4/100: training loss = 0.35498, dev loss = 0.36780, dev f1 score = 0.91952, Time 43m 3s (- 1033m 21s)
Epoch 5/100: training loss = 0.34513, dev loss = 0.27332, dev f1 score = 0.92624, Time 53m 31s (- 1016m 49s)
Update best f1: 0.92233 -> 0.92624, saving model to conv_sampler.pth
Epoch 6/100: training loss = 0.32521, dev loss = 0.27148, dev f1 score = 0.92379, Time 64m 21s (- 1008m 13s)
Epoch 7/100: training loss = 0.29606, dev loss = 0.25399, dev f1 score = 0.92689, Time 74m 47s (- 993m 34s)
Update best f1: 0.92624 -> 0.92689, saving model to conv_sampler.pth
Epoch 8/100: training loss = 0.29534, dev loss = 0.27323, dev f1 score = 0.92189, Time 85m 37s (- 984m 41s)
Epoch 9/100: training loss = 0.28549, dev loss = 0.25700, dev f1 score = 0.92235, Time 96m 3s (- 971m 19s)
Epoch 10/100: training loss = 0.27332, dev loss = 0.31545, dev f1 score = 0.91789, Time 106m 31s (- 958m 41s)
Epoch 11/100: training loss = 0.27035, dev loss = 0.30727, dev f1 score = 0.92446, Time 116m 58s (- 946m 26s)
Epoch 12/100: training loss = 0.26261, dev loss = 0.29860, dev f1 score = 0.92444, Time 127m 25s (- 934m 30s)
Epoch 13/100: training loss = 0.25201, dev loss = 0.27046, dev f1 score = 0.92493, Time 137m 53s (- 922m 46s)
Epoch 14/100: training loss = 0.25754, dev loss = 0.25645, dev f1 score = 0.92297, Time 148m 19s (- 911m 10s)
Epoch 15/100: training loss = 0.24126, dev loss = 0.27653, dev f1 score = 0.92253, Time 158m 46s (- 899m 44s)
Epoch 16/100: training loss = 0.24336, dev loss = 0.36907, dev f1 score = 0.91405, Time 169m 13s (- 888m 26s)
Epoch 17/100: training loss = 0.24159, dev loss = 0.27630, dev f1 score = 0.92240, Time 179m 41s (- 877m 17s)
Epoch 18/100: training loss = 0.23271, dev loss = 0.29192, dev f1 score = 0.92747, Time 190m 7s (- 866m 6s)
Update best f1: 0.92689 -> 0.92747, saving model to conv_sampler.pth
Epoch 19/100: training loss = 0.24722, dev loss = 0.28412, dev f1 score = 0.92631, Time 200m 57s (- 856m 41s)
Epoch 20/100: training loss = 0.22952, dev loss = 0.26330, dev f1 score = 0.92738, Time 211m 22s (- 845m 31s)
Epoch 21/100: training loss = 0.23601, dev loss = 0.31992, dev f1 score = 0.92126, Time 221m 50s (- 834m 31s)
Epoch 22/100: training loss = 0.23044, dev loss = 0.30296, dev f1 score = 0.92190, Time 232m 17s (- 823m 35s)
Epoch 23/100: training loss = 0.22170, dev loss = 0.32175, dev f1 score = 0.92279, Time 242m 45s (- 812m 41s)
Epoch 24/100: training loss = 0.23482, dev loss = 0.30102, dev f1 score = 0.92434, Time 253m 11s (- 801m 47s)
Epoch 25/100: training loss = 0.22622, dev loss = 0.30428, dev f1 score = 0.92420, Time 263m 37s (- 790m 52s)
Epoch 26/100: training loss = 0.22303, dev loss = 0.30205, dev f1 score = 0.92223, Time 274m 4s (- 780m 4s)
Epoch 27/100: training loss = 0.22355, dev loss = 0.28943, dev f1 score = 0.92544, Time 284m 29s (- 769m 10s)
Epoch 28/100: training loss = 0.23263, dev loss = 0.29436, dev f1 score = 0.92178, Time 294m 56s (- 758m 26s)
Epoch 29/100: training loss = 0.22399, dev loss = 0.31426, dev f1 score = 0.92660, Time 305m 23s (- 747m 39s)
Epoch 30/100: training loss = 0.22192, dev loss = 0.32226, dev f1 score = 0.92725, Time 315m 48s (- 736m 53s)
Epoch 31/100: training loss = 0.21939, dev loss = 0.34502, dev f1 score = 0.92587, Time 326m 14s (- 726m 10s)
Epoch 32/100: training loss = 0.22302, dev loss = 0.33567, dev f1 score = 0.92759, Time 336m 41s (- 715m 27s)
Update best f1: 0.92747 -> 0.92759, saving model to conv_sampler.pth
Epoch 33/100: training loss = 0.22135, dev loss = 0.31200, dev f1 score = 0.92631, Time 347m 38s (- 705m 49s)
Epoch 34/100: training loss = 0.21560, dev loss = 0.31181, dev f1 score = 0.92314, Time 358m 4s (- 695m 6s)
Epoch 35/100: training loss = 0.20578, dev loss = 0.33203, dev f1 score = 0.92437, Time 368m 30s (- 684m 23s)
Epoch 36/100: training loss = 0.21319, dev loss = 0.33410, dev f1 score = 0.92216, Time 378m 57s (- 673m 42s)
Epoch 37/100: training loss = 0.21845, dev loss = 0.30805, dev f1 score = 0.92764, Time 389m 24s (- 663m 2s)
Update best f1: 0.92759 -> 0.92764, saving model to conv_sampler.pth
Epoch 38/100: training loss = 0.21428, dev loss = 0.33438, dev f1 score = 0.92326, Time 400m 14s (- 653m 1s)
Epoch 39/100: training loss = 0.21825, dev loss = 0.32668, dev f1 score = 0.92219, Time 410m 40s (- 642m 20s)
Epoch 40/100: training loss = 0.21581, dev loss = 0.33029, dev f1 score = 0.92167, Time 421m 5s (- 631m 37s)
Epoch 41/100: training loss = 0.21768, dev loss = 0.32482, dev f1 score = 0.92847, Time 431m 32s (- 620m 59s)
Update best f1: 0.92764 -> 0.92847, saving model to conv_sampler.pth
Epoch 42/100: training loss = 0.22387, dev loss = 0.33177, dev f1 score = 0.92451, Time 442m 21s (- 610m 52s)
Epoch 43/100: training loss = 0.21701, dev loss = 0.33803, dev f1 score = 0.92571, Time 452m 48s (- 600m 14s)
Epoch 44/100: training loss = 0.21982, dev loss = 0.33231, dev f1 score = 0.92690, Time 463m 16s (- 589m 37s)
Epoch 45/100: training loss = 0.22781, dev loss = 0.31550, dev f1 score = 0.92607, Time 473m 43s (- 579m 0s)
Epoch 46/100: training loss = 0.21675, dev loss = 0.30502, dev f1 score = 0.92208, Time 484m 10s (- 568m 22s)
Epoch 47/100: training loss = 0.21748, dev loss = 0.33026, dev f1 score = 0.92699, Time 494m 36s (- 557m 45s)
Epoch 48/100: training loss = 0.21174, dev loss = 0.31840, dev f1 score = 0.92887, Time 505m 3s (- 547m 8s)
Update best f1: 0.92847 -> 0.92887, saving model to conv_sampler.pth
Epoch 49/100: training loss = 0.21904, dev loss = 0.31654, dev f1 score = 0.92542, Time 515m 56s (- 537m 0s)
Epoch 50/100: training loss = 0.21574, dev loss = 0.32476, dev f1 score = 0.92614, Time 526m 25s (- 526m 25s)
Epoch 51/100: training loss = 0.21465, dev loss = 0.35507, dev f1 score = 0.92698, Time 536m 52s (- 515m 49s)
Epoch 52/100: training loss = 0.22135, dev loss = 0.33453, dev f1 score = 0.92769, Time 547m 20s (- 505m 13s)
Epoch 53/100: training loss = 0.21703, dev loss = 0.33027, dev f1 score = 0.92832, Time 557m 46s (- 494m 37s)
Epoch 54/100: training loss = 0.20874, dev loss = 0.31754, dev f1 score = 0.92595, Time 568m 12s (- 484m 2s)
Epoch 55/100: training loss = 0.21123, dev loss = 0.32922, dev f1 score = 0.92834, Time 578m 39s (- 473m 26s)
Epoch 56/100: training loss = 0.20877, dev loss = 0.32536, dev f1 score = 0.92421, Time 589m 7s (- 462m 52s)
Epoch 57/100: training loss = 0.20263, dev loss = 0.31354, dev f1 score = 0.92769, Time 599m 33s (- 452m 17s)
Epoch 58/100: training loss = 0.19986, dev loss = 0.34596, dev f1 score = 0.92432, Time 609m 59s (- 441m 42s)
Epoch 59/100: training loss = 0.21983, dev loss = 0.34813, dev f1 score = 0.92816, Time 620m 24s (- 431m 8s)
Epoch 60/100: training loss = 0.21205, dev loss = 0.32400, dev f1 score = 0.92726, Time 630m 51s (- 420m 34s)
Epoch 61/100: training loss = 0.20956, dev loss = 0.32833, dev f1 score = 0.92730, Time 641m 18s (- 410m 0s)
Epoch 62/100: training loss = 0.20991, dev loss = 0.32980, dev f1 score = 0.92352, Time 651m 44s (- 399m 27s)
Epoch 63/100: training loss = 0.20958, dev loss = 0.34720, dev f1 score = 0.92534, Time 662m 11s (- 388m 54s)
Epoch 64/100: training loss = 0.21261, dev loss = 0.34267, dev f1 score = 0.92651, Time 672m 39s (- 378m 22s)
Epoch 65/100: training loss = 0.21098, dev loss = 0.32173, dev f1 score = 0.92341, Time 683m 5s (- 367m 48s)
Epoch 66/100: training loss = 0.21421, dev loss = 0.31854, dev f1 score = 0.92803, Time 694m 36s (- 357m 49s)
Epoch 67/100: training loss = 0.20684, dev loss = 0.32626, dev f1 score = 0.92403, Time 705m 4s (- 347m 16s)
Epoch 68/100: training loss = 0.20706, dev loss = 0.33116, dev f1 score = 0.92235, Time 715m 32s (- 336m 43s)
Epoch 69/100: training loss = 0.20649, dev loss = 0.34562, dev f1 score = 0.92522, Time 725m 58s (- 326m 9s)
Epoch 70/100: training loss = 0.21252, dev loss = 0.35134, dev f1 score = 0.92723, Time 736m 25s (- 315m 36s)
Epoch 71/100: training loss = 0.21317, dev loss = 0.33222, dev f1 score = 0.92571, Time 746m 53s (- 305m 3s)
Epoch 72/100: training loss = 0.21419, dev loss = 0.35014, dev f1 score = 0.92476, Time 757m 19s (- 294m 30s)
Epoch 73/100: training loss = 0.20611, dev loss = 0.34533, dev f1 score = 0.92662, Time 767m 45s (- 283m 58s)
Epoch 74/100: training loss = 0.20428, dev loss = 0.37329, dev f1 score = 0.92575, Time 778m 12s (- 273m 25s)
Epoch 75/100: training loss = 0.21097, dev loss = 0.34563, dev f1 score = 0.92539, Time 788m 39s (- 262m 53s)
Epoch 76/100: training loss = 0.20729, dev loss = 0.36514, dev f1 score = 0.92620, Time 799m 7s (- 252m 21s)
Epoch 77/100: training loss = 0.21606, dev loss = 0.34565, dev f1 score = 0.92892, Time 809m 33s (- 241m 48s)
Update best f1: 0.92887 -> 0.92892, saving model to conv_sampler.pth
Epoch 78/100: training loss = 0.20591, dev loss = 0.33127, dev f1 score = 0.92713, Time 820m 28s (- 231m 24s)
Epoch 79/100: training loss = 0.20426, dev loss = 0.37332, dev f1 score = 0.92142, Time 830m 55s (- 220m 52s)
Epoch 80/100: training loss = 0.21882, dev loss = 0.37068, dev f1 score = 0.92503, Time 841m 24s (- 210m 21s)
Epoch 81/100: training loss = 0.20826, dev loss = 0.39251, dev f1 score = 0.92954, Time 851m 52s (- 199m 49s)
Update best f1: 0.92892 -> 0.92954, saving model to conv_sampler.pth
Epoch 82/100: training loss = 0.21132, dev loss = 0.37402, dev f1 score = 0.92484, Time 862m 42s (- 189m 22s)
Epoch 83/100: training loss = 0.20944, dev loss = 0.36237, dev f1 score = 0.92877, Time 873m 10s (- 178m 50s)
Epoch 84/100: training loss = 0.20624, dev loss = 0.36861, dev f1 score = 0.92861, Time 883m 38s (- 168m 18s)
Epoch 85/100: training loss = 0.20609, dev loss = 0.37845, dev f1 score = 0.92826, Time 894m 7s (- 157m 47s)
Epoch 86/100: training loss = 0.20401, dev loss = 0.37126, dev f1 score = 0.92775, Time 904m 34s (- 147m 15s)
Epoch 87/100: training loss = 0.20752, dev loss = 0.33752, dev f1 score = 0.92811, Time 915m 2s (- 136m 43s)
Epoch 88/100: training loss = 0.21564, dev loss = 0.37800, dev f1 score = 0.92550, Time 925m 28s (- 126m 12s)
Epoch 89/100: training loss = 0.21025, dev loss = 0.33760, dev f1 score = 0.92622, Time 935m 54s (- 115m 40s)
Epoch 90/100: training loss = 0.21059, dev loss = 0.34978, dev f1 score = 0.92765, Time 946m 21s (- 105m 9s)
Epoch 91/100: training loss = 0.20410, dev loss = 0.35725, dev f1 score = 0.92839, Time 956m 47s (- 94m 37s)
Epoch 92/100: training loss = 0.21369, dev loss = 0.35188, dev f1 score = 0.93239, Time 967m 14s (- 84m 6s)
Update best f1: 0.92954 -> 0.93239, saving model to conv_sampler.pth
Epoch 93/100: training loss = 0.20039, dev loss = 0.35522, dev f1 score = 0.93092, Time 978m 6s (- 73m 37s)
Epoch 94/100: training loss = 0.21099, dev loss = 0.35807, dev f1 score = 0.92725, Time 988m 34s (- 63m 6s)
Epoch 95/100: training loss = 0.21482, dev loss = 0.35195, dev f1 score = 0.92536, Time 999m 1s (- 52m 34s)
Epoch 96/100: training loss = 0.21324, dev loss = 0.35318, dev f1 score = 0.92736, Time 1009m 28s (- 42m 3s)
Epoch 97/100: training loss = 0.20656, dev loss = 0.39472, dev f1 score = 0.92850, Time 1019m 56s (- 31m 32s)
Epoch 98/100: training loss = 0.20884, dev loss = 0.34562, dev f1 score = 0.92737, Time 1030m 24s (- 21m 1s)
Epoch 99/100: training loss = 0.21182, dev loss = 0.31915, dev f1 score = 0.92671, Time 1040m 55s (- 10m 30s)
Epoch 100/100: training loss = 0.19715, dev loss = 0.34795, dev f1 score = 0.92587, Time 1051m 22s (- 0m 0s)
Best dev f1: 0.93239
