Namespace(batch_size=4, cuda=0, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=30, hw2_QA_bert='../bert.pth', kernel_size=7, learning_rate=5e-06, log_name='parent_pad_6.0.log', merge_type=0, model_name='parent_pad_6.0.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=6.0, round=2000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/30: training loss = 0.47197, dev loss = 0.08198, dev f1 score = 0.95447, Time 10m 59s (- 318m 47s)
Update best f1: 0.00000 -> 0.95447, thres 0.30, saving model to f1_parent_pad_6.0.pth
Update best loss: 1000000000.00000 -> 0.08198, saving model to loss_parent_pad_6.0.pth
Epoch 2/30: training loss = 0.15565, dev loss = 0.08831, dev f1 score = 0.95667, Time 22m 11s (- 310m 34s)
Update best f1: 0.95447 -> 0.95667, thres 0.40, saving model to f1_parent_pad_6.0.pth
Epoch 3/30: training loss = 0.13949, dev loss = 0.13196, dev f1 score = 0.95710, Time 33m 14s (- 299m 13s)
Update best f1: 0.95667 -> 0.95710, thres 0.10, saving model to f1_parent_pad_6.0.pth
Epoch 4/30: training loss = 0.10541, dev loss = 0.07659, dev f1 score = 0.96181, Time 44m 10s (- 287m 5s)
Update best f1: 0.95710 -> 0.96181, thres 0.20, saving model to f1_parent_pad_6.0.pth
Update best loss: 0.08198 -> 0.07659, saving model to loss_parent_pad_6.0.pth
Epoch 5/30: training loss = 0.09506, dev loss = 0.07026, dev f1 score = 0.96276, Time 55m 18s (- 276m 32s)
Update best f1: 0.96181 -> 0.96276, thres 0.50, saving model to f1_parent_pad_6.0.pth
Update best loss: 0.07659 -> 0.07026, saving model to loss_parent_pad_6.0.pth
Epoch 6/30: training loss = 0.08253, dev loss = 0.07384, dev f1 score = 0.95986, Time 66m 30s (- 266m 3s)
Epoch 7/30: training loss = 0.06905, dev loss = 0.07137, dev f1 score = 0.96357, Time 77m 18s (- 253m 59s)
Update best f1: 0.96276 -> 0.96357, thres 0.10, saving model to f1_parent_pad_6.0.pth
Epoch 8/30: training loss = 0.06913, dev loss = 0.07207, dev f1 score = 0.96349, Time 88m 15s (- 242m 43s)
Epoch 9/30: training loss = 0.06419, dev loss = 0.08989, dev f1 score = 0.96229, Time 99m 2s (- 231m 6s)
Epoch 10/30: training loss = 0.06384, dev loss = 0.06730, dev f1 score = 0.96527, Time 109m 54s (- 219m 49s)
Update best f1: 0.96357 -> 0.96527, thres 0.50, saving model to f1_parent_pad_6.0.pth
Update best loss: 0.07026 -> 0.06730, saving model to loss_parent_pad_6.0.pth
Epoch 11/30: training loss = 0.06209, dev loss = 0.06036, dev f1 score = 0.96429, Time 121m 3s (- 209m 6s)
Update best loss: 0.06730 -> 0.06036, saving model to loss_parent_pad_6.0.pth
Epoch 12/30: training loss = 0.05680, dev loss = 0.07521, dev f1 score = 0.96477, Time 132m 4s (- 198m 6s)
Epoch 13/30: training loss = 0.05678, dev loss = 0.06166, dev f1 score = 0.96554, Time 142m 50s (- 186m 48s)
Update best f1: 0.96527 -> 0.96554, thres 0.30, saving model to f1_parent_pad_6.0.pth
Epoch 14/30: training loss = 0.05555, dev loss = 0.06498, dev f1 score = 0.96553, Time 153m 44s (- 175m 42s)
Epoch 15/30: training loss = 0.05024, dev loss = 0.05978, dev f1 score = 0.96528, Time 164m 26s (- 164m 26s)
Update best loss: 0.06036 -> 0.05978, saving model to loss_parent_pad_6.0.pth
Epoch 16/30: training loss = 0.05607, dev loss = 0.06078, dev f1 score = 0.96550, Time 175m 22s (- 153m 27s)
Epoch 17/30: training loss = 0.04864, dev loss = 0.06682, dev f1 score = 0.96604, Time 186m 9s (- 142m 21s)
Update best f1: 0.96554 -> 0.96604, thres 0.20, saving model to f1_parent_pad_6.0.pth
Epoch 18/30: training loss = 0.04623, dev loss = 0.07117, dev f1 score = 0.96477, Time 197m 3s (- 131m 22s)
Epoch 19/30: training loss = 0.05260, dev loss = 0.07135, dev f1 score = 0.96363, Time 207m 48s (- 120m 18s)
Epoch 20/30: training loss = 0.04672, dev loss = 0.07208, dev f1 score = 0.96682, Time 218m 29s (- 109m 14s)
Update best f1: 0.96604 -> 0.96682, thres 0.40, saving model to f1_parent_pad_6.0.pth
Epoch 21/30: training loss = 0.04785, dev loss = 0.06104, dev f1 score = 0.96833, Time 229m 23s (- 98m 18s)
Update best f1: 0.96682 -> 0.96833, thres 0.50, saving model to f1_parent_pad_6.0.pth
Epoch 22/30: training loss = 0.04344, dev loss = 0.05941, dev f1 score = 0.96713, Time 240m 19s (- 87m 23s)
Update best loss: 0.05978 -> 0.05941, saving model to loss_parent_pad_6.0.pth
Epoch 23/30: training loss = 0.04474, dev loss = 0.05799, dev f1 score = 0.96608, Time 251m 14s (- 76m 27s)
Update best loss: 0.05941 -> 0.05799, saving model to loss_parent_pad_6.0.pth
Epoch 24/30: training loss = 0.03811, dev loss = 0.06400, dev f1 score = 0.96774, Time 262m 4s (- 65m 31s)
Epoch 25/30: training loss = 0.05020, dev loss = 0.05564, dev f1 score = 0.96866, Time 272m 46s (- 54m 33s)
Update best f1: 0.96833 -> 0.96866, thres 0.60, saving model to f1_parent_pad_6.0.pth
Update best loss: 0.05799 -> 0.05564, saving model to loss_parent_pad_6.0.pth
Epoch 26/30: training loss = 0.03907, dev loss = 0.07776, dev f1 score = 0.96688, Time 284m 3s (- 43m 42s)
Epoch 27/30: training loss = 0.04118, dev loss = 0.08119, dev f1 score = 0.96677, Time 295m 4s (- 32m 47s)
Epoch 28/30: training loss = 0.03931, dev loss = 0.06971, dev f1 score = 0.96762, Time 305m 50s (- 21m 50s)
Epoch 29/30: training loss = 0.04458, dev loss = 0.06791, dev f1 score = 0.96852, Time 316m 34s (- 10m 54s)
Epoch 30/30: training loss = 0.03231, dev loss = 0.08358, dev f1 score = 0.96558, Time 327m 18s (- 0m 0s)
Best dev f1: 0.96866 Best dev loss: 0.05564
