Namespace(cuda=0, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=100, kernel_size=7, learning_rate=5e-06, log_name='conv2.log', model_name='conv2.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=None, round=1000, train='conv2', train_data='../release/train', use_sampler=False)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/100: training loss = 0.95316, dev loss = 0.45690, dev f1 score = 0.89160, Time 9m 24s (- 930m 52s)
Update best f1: 0.00000 -> 0.89160, saving model to conv2.pth
Epoch 2/100: training loss = 0.33859, dev loss = 0.30211, dev f1 score = 0.91789, Time 19m 5s (- 935m 20s)
Update best f1: 0.89160 -> 0.91789, saving model to conv2.pth
Epoch 3/100: training loss = 0.24189, dev loss = 0.28216, dev f1 score = 0.91832, Time 28m 49s (- 932m 8s)
Update best f1: 0.91789 -> 0.91832, saving model to conv2.pth
Epoch 4/100: training loss = 0.20814, dev loss = 0.25829, dev f1 score = 0.92219, Time 38m 34s (- 925m 51s)
Update best f1: 0.91832 -> 0.92219, saving model to conv2.pth
Epoch 5/100: training loss = 0.18804, dev loss = 0.23497, dev f1 score = 0.92185, Time 48m 28s (- 921m 9s)
Epoch 6/100: training loss = 0.17194, dev loss = 0.24312, dev f1 score = 0.92136, Time 57m 54s (- 907m 18s)
Epoch 7/100: training loss = 0.15880, dev loss = 0.25570, dev f1 score = 0.92553, Time 67m 21s (- 894m 52s)
Update best f1: 0.92219 -> 0.92553, saving model to conv2.pth
Epoch 8/100: training loss = 0.15025, dev loss = 0.26908, dev f1 score = 0.92146, Time 77m 1s (- 885m 48s)
Epoch 9/100: training loss = 0.14236, dev loss = 0.26206, dev f1 score = 0.92422, Time 86m 28s (- 874m 19s)
Epoch 10/100: training loss = 0.13826, dev loss = 0.25197, dev f1 score = 0.92799, Time 95m 53s (- 863m 5s)
Update best f1: 0.92553 -> 0.92799, saving model to conv2.pth
Epoch 11/100: training loss = 0.12769, dev loss = 0.26207, dev f1 score = 0.92847, Time 105m 43s (- 855m 23s)
Update best f1: 0.92799 -> 0.92847, saving model to conv2.pth
Epoch 12/100: training loss = 0.12733, dev loss = 0.28715, dev f1 score = 0.92341, Time 115m 37s (- 847m 58s)
Epoch 13/100: training loss = 0.12167, dev loss = 0.25773, dev f1 score = 0.92114, Time 125m 4s (- 836m 59s)
Epoch 14/100: training loss = 0.11861, dev loss = 0.27323, dev f1 score = 0.92535, Time 134m 28s (- 826m 0s)
Epoch 15/100: training loss = 0.11510, dev loss = 0.26433, dev f1 score = 0.92294, Time 143m 51s (- 815m 9s)
Epoch 16/100: training loss = 0.11260, dev loss = 0.26681, dev f1 score = 0.92222, Time 153m 16s (- 804m 41s)
Epoch 17/100: training loss = 0.11031, dev loss = 0.27878, dev f1 score = 0.92529, Time 162m 40s (- 794m 13s)
Epoch 18/100: training loss = 0.10792, dev loss = 0.30590, dev f1 score = 0.92088, Time 172m 4s (- 783m 54s)
Epoch 19/100: training loss = 0.10590, dev loss = 0.31425, dev f1 score = 0.92786, Time 181m 30s (- 773m 48s)
Epoch 20/100: training loss = 0.10378, dev loss = 0.27570, dev f1 score = 0.92448, Time 190m 55s (- 763m 40s)
Epoch 21/100: training loss = 0.10415, dev loss = 0.29583, dev f1 score = 0.92280, Time 200m 17s (- 753m 29s)
Epoch 22/100: training loss = 0.10575, dev loss = 0.26397, dev f1 score = 0.92834, Time 209m 42s (- 743m 32s)
Epoch 23/100: training loss = 0.10160, dev loss = 0.29436, dev f1 score = 0.92484, Time 219m 7s (- 733m 35s)
Epoch 24/100: training loss = 0.09812, dev loss = 0.31032, dev f1 score = 0.91996, Time 228m 29s (- 723m 34s)
Epoch 25/100: training loss = 0.10039, dev loss = 0.30251, dev f1 score = 0.92889, Time 237m 55s (- 713m 45s)
Update best f1: 0.92847 -> 0.92889, saving model to conv2.pth
Epoch 26/100: training loss = 0.10125, dev loss = 0.27927, dev f1 score = 0.92263, Time 247m 43s (- 705m 3s)
Epoch 27/100: training loss = 0.09798, dev loss = 0.29559, dev f1 score = 0.92443, Time 257m 7s (- 695m 10s)
Epoch 28/100: training loss = 0.09827, dev loss = 0.31258, dev f1 score = 0.92704, Time 266m 31s (- 685m 21s)
Epoch 29/100: training loss = 0.09218, dev loss = 0.32144, dev f1 score = 0.93124, Time 275m 56s (- 675m 34s)
Update best f1: 0.92889 -> 0.93124, saving model to conv2.pth
Epoch 30/100: training loss = 0.09655, dev loss = 0.30222, dev f1 score = 0.92637, Time 285m 42s (- 666m 40s)
Epoch 31/100: training loss = 0.09574, dev loss = 0.32962, dev f1 score = 0.92567, Time 295m 7s (- 656m 53s)
Epoch 32/100: training loss = 0.09450, dev loss = 0.33052, dev f1 score = 0.92500, Time 304m 4s (- 646m 9s)
Epoch 33/100: training loss = 0.09167, dev loss = 0.34698, dev f1 score = 0.92937, Time 313m 28s (- 636m 26s)
Epoch 34/100: training loss = 0.09518, dev loss = 0.30260, dev f1 score = 0.92599, Time 322m 52s (- 626m 44s)
Epoch 35/100: training loss = 0.09378, dev loss = 0.30887, dev f1 score = 0.92438, Time 332m 18s (- 617m 7s)
Epoch 36/100: training loss = 0.09317, dev loss = 0.31197, dev f1 score = 0.92858, Time 341m 41s (- 607m 27s)
Epoch 37/100: training loss = 0.09130, dev loss = 0.32716, dev f1 score = 0.92028, Time 351m 7s (- 597m 51s)
Epoch 38/100: training loss = 0.09311, dev loss = 0.31356, dev f1 score = 0.92426, Time 360m 33s (- 588m 16s)
Epoch 39/100: training loss = 0.09316, dev loss = 0.33265, dev f1 score = 0.92629, Time 369m 53s (- 578m 33s)
Epoch 40/100: training loss = 0.08979, dev loss = 0.33668, dev f1 score = 0.92786, Time 379m 18s (- 568m 57s)
