Namespace(batch_size=4, cuda=1, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=30, hw2_QA_bert='../bert.pth', kernel_size=7, learning_rate=5e-06, log_name='parent_pad_4.0.log', merge_type=0, model_name='parent_pad_4.0.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=4.0, round=2000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/30: training loss = 0.44455, dev loss = 0.08727, dev f1 score = 0.93905, Time 13m 24s (- 388m 40s)
Update best f1: 0.00000 -> 0.93905, thres 0.40, saving model to f1_parent_pad_4.0.pth
Update best loss: 1000000000.00000 -> 0.08727, saving model to loss_parent_pad_4.0.pth
Epoch 2/30: training loss = 0.15163, dev loss = 0.11012, dev f1 score = 0.95740, Time 27m 15s (- 381m 30s)
Update best f1: 0.93905 -> 0.95740, thres 0.10, saving model to f1_parent_pad_4.0.pth
Epoch 3/30: training loss = 0.11274, dev loss = 0.06138, dev f1 score = 0.95539, Time 40m 48s (- 367m 13s)
Update best loss: 0.08727 -> 0.06138, saving model to loss_parent_pad_4.0.pth
Epoch 4/30: training loss = 0.09451, dev loss = 0.06584, dev f1 score = 0.96467, Time 54m 21s (- 353m 18s)
Update best f1: 0.95740 -> 0.96467, thres 0.30, saving model to f1_parent_pad_4.0.pth
Epoch 5/30: training loss = 0.08808, dev loss = 0.06000, dev f1 score = 0.96076, Time 67m 48s (- 339m 0s)
Update best loss: 0.06138 -> 0.06000, saving model to loss_parent_pad_4.0.pth
Epoch 6/30: training loss = 0.07769, dev loss = 0.04897, dev f1 score = 0.96591, Time 81m 26s (- 325m 47s)
Update best f1: 0.96467 -> 0.96591, thres 0.40, saving model to f1_parent_pad_4.0.pth
Update best loss: 0.06000 -> 0.04897, saving model to loss_parent_pad_4.0.pth
Epoch 7/30: training loss = 0.06801, dev loss = 0.05420, dev f1 score = 0.96511, Time 95m 6s (- 312m 30s)
Epoch 8/30: training loss = 0.06242, dev loss = 0.07025, dev f1 score = 0.96579, Time 108m 36s (- 298m 41s)
Epoch 9/30: training loss = 0.06881, dev loss = 0.05959, dev f1 score = 0.96539, Time 121m 51s (- 284m 19s)
Epoch 10/30: training loss = 0.05390, dev loss = 0.05738, dev f1 score = 0.96566, Time 134m 57s (- 269m 55s)
Epoch 11/30: training loss = 0.06014, dev loss = 0.04852, dev f1 score = 0.96582, Time 148m 7s (- 255m 50s)
Update best loss: 0.04897 -> 0.04852, saving model to loss_parent_pad_4.0.pth
Epoch 12/30: training loss = 0.05548, dev loss = 0.05089, dev f1 score = 0.96593, Time 161m 27s (- 242m 11s)
Update best f1: 0.96591 -> 0.96593, thres 0.60, saving model to f1_parent_pad_4.0.pth
Epoch 13/30: training loss = 0.05083, dev loss = 0.06808, dev f1 score = 0.96235, Time 174m 57s (- 228m 47s)
Epoch 14/30: training loss = 0.04995, dev loss = 0.06340, dev f1 score = 0.96255, Time 188m 10s (- 215m 3s)
Epoch 15/30: training loss = 0.04613, dev loss = 0.08790, dev f1 score = 0.96493, Time 201m 30s (- 201m 30s)
Epoch 16/30: training loss = 0.04480, dev loss = 0.05653, dev f1 score = 0.96364, Time 214m 50s (- 187m 59s)
Epoch 17/30: training loss = 0.04734, dev loss = 0.07073, dev f1 score = 0.96265, Time 228m 9s (- 174m 28s)
Epoch 18/30: training loss = 0.04452, dev loss = 0.05950, dev f1 score = 0.96692, Time 241m 15s (- 160m 50s)
Update best f1: 0.96593 -> 0.96692, thres 0.50, saving model to f1_parent_pad_4.0.pth
Epoch 19/30: training loss = 0.04282, dev loss = 0.05666, dev f1 score = 0.96189, Time 254m 49s (- 147m 31s)
Epoch 20/30: training loss = 0.03677, dev loss = 0.06151, dev f1 score = 0.96188, Time 267m 55s (- 133m 57s)
Epoch 21/30: training loss = 0.04388, dev loss = 0.06211, dev f1 score = 0.96717, Time 281m 14s (- 120m 31s)
Update best f1: 0.96692 -> 0.96717, thres 0.20, saving model to f1_parent_pad_4.0.pth
Epoch 22/30: training loss = 0.03930, dev loss = 0.05813, dev f1 score = 0.96550, Time 294m 28s (- 107m 4s)
Epoch 23/30: training loss = 0.04114, dev loss = 0.06393, dev f1 score = 0.96508, Time 307m 34s (- 93m 36s)
Epoch 24/30: training loss = 0.03989, dev loss = 0.07881, dev f1 score = 0.96442, Time 321m 1s (- 80m 15s)
Epoch 25/30: training loss = 0.03456, dev loss = 0.05776, dev f1 score = 0.96558, Time 334m 25s (- 66m 53s)
Epoch 26/30: training loss = 0.03502, dev loss = 0.05681, dev f1 score = 0.96475, Time 347m 42s (- 53m 29s)
Epoch 27/30: training loss = 0.03467, dev loss = 0.06024, dev f1 score = 0.96288, Time 361m 26s (- 40m 9s)
Epoch 28/30: training loss = 0.04071, dev loss = 0.05853, dev f1 score = 0.96470, Time 375m 18s (- 26m 48s)
Epoch 29/30: training loss = 0.03668, dev loss = 0.05848, dev f1 score = 0.96670, Time 389m 9s (- 13m 25s)
Epoch 30/30: training loss = 0.03485, dev loss = 0.05570, dev f1 score = 0.96383, Time 402m 47s (- 0m 0s)
Best dev f1: 0.96717 Best dev loss: 0.04852
