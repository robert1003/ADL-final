Namespace(cuda=0, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=100, hw2_QA_bert='bert.pth', kernel_size=7, learning_rate=5e-06, log_name='conv_hw2.log', model_name='conv_hw2.pth', pretrained_model='bert-base-multilingual-cased', ratio=2.0, round=1000, train='conv', train_data='../release/train', use_sampler=True)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 119547
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/100: training loss = 1.08637, dev loss = 0.37675, dev f1 score = 0.90107, Time 3m 32s (- 350m 24s)
Update best f1: 0.00000 -> 0.90107, saving model to conv_hw2.pth
Epoch 2/100: training loss = 0.41382, dev loss = 0.30472, dev f1 score = 0.91675, Time 7m 31s (- 368m 38s)
Update best f1: 0.90107 -> 0.91675, saving model to conv_hw2.pth
Epoch 3/100: training loss = 0.34100, dev loss = 0.30699, dev f1 score = 0.92131, Time 11m 35s (- 374m 40s)
Update best f1: 0.91675 -> 0.92131, saving model to conv_hw2.pth
Epoch 4/100: training loss = 0.30609, dev loss = 0.27805, dev f1 score = 0.92376, Time 15m 35s (- 374m 12s)
Update best f1: 0.92131 -> 0.92376, saving model to conv_hw2.pth
Epoch 5/100: training loss = 0.28835, dev loss = 0.27203, dev f1 score = 0.92295, Time 19m 33s (- 371m 33s)
Epoch 6/100: training loss = 0.25144, dev loss = 0.25239, dev f1 score = 0.92520, Time 23m 9s (- 362m 42s)
Update best f1: 0.92376 -> 0.92520, saving model to conv_hw2.pth
Epoch 7/100: training loss = 0.23812, dev loss = 0.22901, dev f1 score = 0.92266, Time 27m 10s (- 361m 7s)
Epoch 8/100: training loss = 0.25164, dev loss = 0.24282, dev f1 score = 0.92153, Time 30m 47s (- 354m 1s)
Epoch 9/100: training loss = 0.24238, dev loss = 0.23410, dev f1 score = 0.92563, Time 34m 22s (- 347m 38s)
Update best f1: 0.92520 -> 0.92563, saving model to conv_hw2.pth
Epoch 10/100: training loss = 0.23287, dev loss = 0.22281, dev f1 score = 0.92665, Time 38m 34s (- 347m 11s)
Update best f1: 0.92563 -> 0.92665, saving model to conv_hw2.pth
Epoch 11/100: training loss = 0.21901, dev loss = 0.24408, dev f1 score = 0.92648, Time 42m 34s (- 344m 30s)
Epoch 12/100: training loss = 0.20522, dev loss = 0.21556, dev f1 score = 0.92218, Time 46m 10s (- 338m 37s)
Epoch 13/100: training loss = 0.22395, dev loss = 0.21213, dev f1 score = 0.92507, Time 49m 46s (- 333m 8s)
Epoch 14/100: training loss = 0.20609, dev loss = 0.23056, dev f1 score = 0.92461, Time 53m 23s (- 327m 56s)
Epoch 15/100: training loss = 0.20646, dev loss = 0.21841, dev f1 score = 0.92568, Time 56m 59s (- 322m 54s)
Epoch 16/100: training loss = 0.19678, dev loss = 0.22416, dev f1 score = 0.92813, Time 60m 34s (- 318m 3s)
Update best f1: 0.92665 -> 0.92813, saving model to conv_hw2.pth
Epoch 17/100: training loss = 0.18859, dev loss = 0.23279, dev f1 score = 0.92769, Time 64m 42s (- 315m 54s)
Epoch 18/100: training loss = 0.19635, dev loss = 0.21924, dev f1 score = 0.92557, Time 68m 17s (- 311m 8s)
Epoch 19/100: training loss = 0.18820, dev loss = 0.25192, dev f1 score = 0.92673, Time 71m 53s (- 306m 29s)
Epoch 20/100: training loss = 0.18497, dev loss = 0.25233, dev f1 score = 0.92564, Time 75m 29s (- 301m 57s)
Epoch 21/100: training loss = 0.18325, dev loss = 0.23770, dev f1 score = 0.92544, Time 79m 5s (- 297m 30s)
Epoch 22/100: training loss = 0.17153, dev loss = 0.25259, dev f1 score = 0.92446, Time 82m 41s (- 293m 10s)
Epoch 23/100: training loss = 0.17408, dev loss = 0.25642, dev f1 score = 0.92384, Time 86m 17s (- 288m 52s)
Epoch 24/100: training loss = 0.17957, dev loss = 0.26683, dev f1 score = 0.92108, Time 89m 52s (- 284m 37s)
Epoch 25/100: training loss = 0.16926, dev loss = 0.26368, dev f1 score = 0.92326, Time 93m 28s (- 280m 26s)
Epoch 26/100: training loss = 0.17273, dev loss = 0.23757, dev f1 score = 0.92568, Time 97m 4s (- 276m 16s)
Epoch 27/100: training loss = 0.17600, dev loss = 0.26351, dev f1 score = 0.92481, Time 100m 39s (- 272m 10s)
Epoch 28/100: training loss = 0.17351, dev loss = 0.25701, dev f1 score = 0.92249, Time 104m 15s (- 268m 5s)
Epoch 29/100: training loss = 0.18124, dev loss = 0.23729, dev f1 score = 0.92536, Time 107m 51s (- 264m 3s)
Epoch 30/100: training loss = 0.16280, dev loss = 0.26543, dev f1 score = 0.92598, Time 111m 27s (- 260m 3s)
Epoch 31/100: training loss = 0.16555, dev loss = 0.26162, dev f1 score = 0.92152, Time 115m 3s (- 256m 4s)
Epoch 32/100: training loss = 0.16336, dev loss = 0.24557, dev f1 score = 0.92639, Time 118m 38s (- 252m 7s)
Epoch 33/100: training loss = 0.16362, dev loss = 0.24662, dev f1 score = 0.92051, Time 122m 14s (- 248m 11s)
Epoch 34/100: training loss = 0.16737, dev loss = 0.26354, dev f1 score = 0.92542, Time 125m 50s (- 244m 17s)
Epoch 35/100: training loss = 0.15285, dev loss = 0.25732, dev f1 score = 0.92258, Time 129m 26s (- 240m 23s)
Epoch 36/100: training loss = 0.16111, dev loss = 0.27318, dev f1 score = 0.92160, Time 133m 2s (- 236m 30s)
Epoch 37/100: training loss = 0.17605, dev loss = 0.27697, dev f1 score = 0.92467, Time 136m 38s (- 232m 38s)
Epoch 38/100: training loss = 0.15026, dev loss = 0.25693, dev f1 score = 0.92200, Time 140m 14s (- 228m 48s)
Epoch 39/100: training loss = 0.16064, dev loss = 0.25868, dev f1 score = 0.92638, Time 143m 50s (- 224m 59s)
Epoch 40/100: training loss = 0.16484, dev loss = 0.26995, dev f1 score = 0.92692, Time 147m 26s (- 221m 10s)
Epoch 41/100: training loss = 0.15332, dev loss = 0.32996, dev f1 score = 0.92224, Time 151m 2s (- 217m 21s)
Epoch 42/100: training loss = 0.14598, dev loss = 0.30366, dev f1 score = 0.92329, Time 154m 38s (- 213m 33s)
Epoch 43/100: training loss = 0.13993, dev loss = 0.28296, dev f1 score = 0.92638, Time 158m 14s (- 209m 45s)
Epoch 44/100: training loss = 0.15547, dev loss = 0.31480, dev f1 score = 0.92365, Time 161m 50s (- 205m 58s)
Epoch 45/100: training loss = 0.14869, dev loss = 0.28869, dev f1 score = 0.92563, Time 165m 26s (- 202m 12s)
Epoch 46/100: training loss = 0.14977, dev loss = 0.28728, dev f1 score = 0.92587, Time 169m 2s (- 198m 26s)
Epoch 47/100: training loss = 0.14594, dev loss = 0.30498, dev f1 score = 0.92488, Time 172m 39s (- 194m 41s)
Epoch 48/100: training loss = 0.15184, dev loss = 0.29971, dev f1 score = 0.92192, Time 176m 15s (- 190m 57s)
Epoch 49/100: training loss = 0.15334, dev loss = 0.31266, dev f1 score = 0.92229, Time 179m 52s (- 187m 12s)
Epoch 50/100: training loss = 0.16316, dev loss = 0.26894, dev f1 score = 0.92858, Time 183m 28s (- 183m 28s)
Update best f1: 0.92813 -> 0.92858, saving model to conv_hw2.pth
Epoch 51/100: training loss = 0.14945, dev loss = 0.29337, dev f1 score = 0.92624, Time 187m 28s (- 180m 7s)
Epoch 52/100: training loss = 0.15279, dev loss = 0.28357, dev f1 score = 0.92291, Time 191m 5s (- 176m 23s)
Epoch 53/100: training loss = 0.15078, dev loss = 0.28585, dev f1 score = 0.92491, Time 194m 42s (- 172m 39s)
Epoch 54/100: training loss = 0.14691, dev loss = 0.27946, dev f1 score = 0.92609, Time 198m 18s (- 168m 56s)
Epoch 55/100: training loss = 0.15833, dev loss = 0.31035, dev f1 score = 0.92142, Time 201m 55s (- 165m 13s)
Epoch 56/100: training loss = 0.14653, dev loss = 0.26695, dev f1 score = 0.92692, Time 205m 32s (- 161m 30s)
Epoch 57/100: training loss = 0.14713, dev loss = 0.29372, dev f1 score = 0.92906, Time 209m 9s (- 157m 47s)
Update best f1: 0.92858 -> 0.92906, saving model to conv_hw2.pth
Epoch 58/100: training loss = 0.14770, dev loss = 0.29421, dev f1 score = 0.92540, Time 213m 8s (- 154m 20s)
Epoch 59/100: training loss = 0.15330, dev loss = 0.29150, dev f1 score = 0.92630, Time 216m 46s (- 150m 38s)
Epoch 60/100: training loss = 0.15670, dev loss = 0.29765, dev f1 score = 0.92606, Time 220m 23s (- 146m 55s)
Epoch 61/100: training loss = 0.13861, dev loss = 0.32018, dev f1 score = 0.92472, Time 223m 59s (- 143m 12s)
Epoch 62/100: training loss = 0.15280, dev loss = 0.28270, dev f1 score = 0.92526, Time 227m 35s (- 139m 29s)
Epoch 63/100: training loss = 0.14840, dev loss = 0.30954, dev f1 score = 0.92751, Time 231m 11s (- 135m 46s)
Epoch 64/100: training loss = 0.14936, dev loss = 0.29031, dev f1 score = 0.92465, Time 234m 48s (- 132m 4s)
Epoch 65/100: training loss = 0.14460, dev loss = 0.30489, dev f1 score = 0.92351, Time 238m 24s (- 128m 22s)
Epoch 66/100: training loss = 0.15464, dev loss = 0.29881, dev f1 score = 0.92477, Time 242m 0s (- 124m 40s)
Epoch 67/100: training loss = 0.15018, dev loss = 0.29452, dev f1 score = 0.92506, Time 245m 35s (- 120m 58s)
Epoch 68/100: training loss = 0.14341, dev loss = 0.29818, dev f1 score = 0.92601, Time 249m 11s (- 117m 16s)
Epoch 69/100: training loss = 0.14386, dev loss = 0.31151, dev f1 score = 0.92308, Time 252m 47s (- 113m 34s)
Epoch 70/100: training loss = 0.15865, dev loss = 0.32585, dev f1 score = 0.92396, Time 256m 23s (- 109m 52s)
Epoch 71/100: training loss = 0.14206, dev loss = 0.31634, dev f1 score = 0.92474, Time 259m 59s (- 106m 11s)
Epoch 72/100: training loss = 0.14931, dev loss = 0.29532, dev f1 score = 0.92955, Time 263m 35s (- 102m 30s)
Update best f1: 0.92906 -> 0.92955, saving model to conv_hw2.pth
Epoch 73/100: training loss = 0.14104, dev loss = 0.32534, dev f1 score = 0.92871, Time 267m 35s (- 98m 58s)
Epoch 74/100: training loss = 0.14099, dev loss = 0.29493, dev f1 score = 0.92286, Time 271m 11s (- 95m 17s)
Epoch 75/100: training loss = 0.15520, dev loss = 0.25664, dev f1 score = 0.92647, Time 274m 48s (- 91m 36s)
Epoch 76/100: training loss = 0.14721, dev loss = 0.28928, dev f1 score = 0.92563, Time 278m 25s (- 87m 55s)
Epoch 77/100: training loss = 0.12570, dev loss = 0.30302, dev f1 score = 0.92758, Time 282m 3s (- 84m 14s)
Epoch 78/100: training loss = 0.14901, dev loss = 0.30253, dev f1 score = 0.91994, Time 285m 39s (- 80m 34s)
Epoch 79/100: training loss = 0.14179, dev loss = 0.28626, dev f1 score = 0.92621, Time 289m 15s (- 76m 53s)
Epoch 80/100: training loss = 0.13533, dev loss = 0.28091, dev f1 score = 0.92441, Time 292m 51s (- 73m 12s)
Epoch 81/100: training loss = 0.14783, dev loss = 0.28765, dev f1 score = 0.92619, Time 296m 27s (- 69m 32s)
Epoch 82/100: training loss = 0.14524, dev loss = 0.29799, dev f1 score = 0.92390, Time 300m 3s (- 65m 52s)
Epoch 83/100: training loss = 0.14940, dev loss = 0.29865, dev f1 score = 0.92331, Time 303m 39s (- 62m 11s)
Epoch 84/100: training loss = 0.14502, dev loss = 0.29837, dev f1 score = 0.92835, Time 307m 15s (- 58m 31s)
Epoch 85/100: training loss = 0.12744, dev loss = 0.30701, dev f1 score = 0.92902, Time 310m 51s (- 54m 51s)
Epoch 86/100: training loss = 0.14987, dev loss = 0.30817, dev f1 score = 0.93106, Time 314m 27s (- 51m 11s)
Update best f1: 0.92955 -> 0.93106, saving model to conv_hw2.pth
Epoch 87/100: training loss = 0.14432, dev loss = 0.30308, dev f1 score = 0.92325, Time 318m 26s (- 47m 34s)
Epoch 88/100: training loss = 0.14954, dev loss = 0.30906, dev f1 score = 0.92356, Time 322m 2s (- 43m 54s)
Epoch 89/100: training loss = 0.14356, dev loss = 0.32172, dev f1 score = 0.92218, Time 325m 38s (- 40m 14s)
Epoch 90/100: training loss = 0.14844, dev loss = 0.30030, dev f1 score = 0.92685, Time 329m 14s (- 36m 34s)
Epoch 91/100: training loss = 0.13942, dev loss = 0.32927, dev f1 score = 0.92503, Time 332m 50s (- 32m 55s)
Epoch 92/100: training loss = 0.14680, dev loss = 0.29085, dev f1 score = 0.92950, Time 336m 27s (- 29m 15s)
Epoch 93/100: training loss = 0.14394, dev loss = 0.31389, dev f1 score = 0.93018, Time 340m 3s (- 25m 35s)
Epoch 94/100: training loss = 0.14579, dev loss = 0.32459, dev f1 score = 0.92466, Time 343m 39s (- 21m 56s)
Epoch 95/100: training loss = 0.14510, dev loss = 0.31705, dev f1 score = 0.92542, Time 347m 15s (- 18m 16s)
Epoch 96/100: training loss = 0.14098, dev loss = 0.31641, dev f1 score = 0.92711, Time 350m 51s (- 14m 37s)
Epoch 97/100: training loss = 0.15590, dev loss = 0.32063, dev f1 score = 0.92654, Time 354m 27s (- 10m 57s)
Epoch 98/100: training loss = 0.14031, dev loss = 0.30679, dev f1 score = 0.92867, Time 358m 3s (- 7m 18s)
Epoch 99/100: training loss = 0.15259, dev loss = 0.27350, dev f1 score = 0.93144, Time 361m 39s (- 3m 39s)
Update best f1: 0.93106 -> 0.93144, saving model to conv_hw2.pth
Epoch 100/100: training loss = 0.14440, dev loss = 0.28629, dev f1 score = 0.92985, Time 365m 38s (- 0m 0s)
Best dev f1: 0.93144
