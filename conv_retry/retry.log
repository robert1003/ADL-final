Namespace(batch_size=4, cuda=1, dev_data='../release/dev', dev_ref_file='../release/dev/dev_ref.csv', epochs=20, hw2_QA_bert=None, kernel_size=7, learning_rate=3e-05, log_name='retry.log', merge_type=0, model_name='retry.pth', overlap_k=0, pretrained_model='bert-base-multilingual-cased', ratio=None, round=1000, train='conv', train_data='../release/train', use_sampler=False)
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/robert1003/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/robert1003/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/robert1003/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059
Epoch 1/20: training loss = 0.57846, dev loss = 0.36866, dev f1 score = 0.88714, Time 13m 3s (- 248m 8s)
Update best f1: 0.00000 -> 0.88714, thres 0.50, saving model to f1_retry.pth
Update best loss: 1000000000.00000 -> 0.36866, saving model to loss_retry.pth
Epoch 2/20: training loss = 0.25652, dev loss = 0.21728, dev f1 score = 0.92238, Time 26m 38s (- 239m 44s)
Update best f1: 0.88714 -> 0.92238, thres 0.50, saving model to f1_retry.pth
Update best loss: 0.36866 -> 0.21728, saving model to loss_retry.pth
Epoch 3/20: training loss = 0.19601, dev loss = 0.28568, dev f1 score = 0.92048, Time 40m 13s (- 227m 58s)
Epoch 4/20: training loss = 0.16715, dev loss = 0.25280, dev f1 score = 0.93084, Time 53m 24s (- 213m 39s)
Update best f1: 0.92238 -> 0.93084, thres 0.60, saving model to f1_retry.pth
Epoch 5/20: training loss = 0.15023, dev loss = 0.21029, dev f1 score = 0.92942, Time 66m 45s (- 200m 16s)
Update best loss: 0.21728 -> 0.21029, saving model to loss_retry.pth
Epoch 6/20: training loss = 0.13510, dev loss = 0.21473, dev f1 score = 0.92762, Time 80m 7s (- 186m 56s)
Epoch 7/20: training loss = 0.12223, dev loss = 0.21795, dev f1 score = 0.92750, Time 93m 18s (- 173m 17s)
Epoch 8/20: training loss = 0.11279, dev loss = 0.21285, dev f1 score = 0.92615, Time 106m 32s (- 159m 48s)
Epoch 9/20: training loss = 0.10998, dev loss = 0.21955, dev f1 score = 0.93458, Time 119m 42s (- 146m 19s)
Update best f1: 0.93084 -> 0.93458, thres 0.20, saving model to f1_retry.pth
Epoch 10/20: training loss = 0.09719, dev loss = 0.19300, dev f1 score = 0.93567, Time 133m 5s (- 133m 5s)
Update best f1: 0.93458 -> 0.93567, thres 0.40, saving model to f1_retry.pth
Update best loss: 0.21029 -> 0.19300, saving model to loss_retry.pth
Epoch 11/20: training loss = 0.08939, dev loss = 0.22111, dev f1 score = 0.92646, Time 146m 36s (- 119m 56s)
Epoch 12/20: training loss = 0.08554, dev loss = 0.24676, dev f1 score = 0.93253, Time 159m 45s (- 106m 30s)
Epoch 13/20: training loss = 0.08274, dev loss = 0.22318, dev f1 score = 0.93062, Time 172m 52s (- 93m 5s)
Epoch 14/20: training loss = 0.06998, dev loss = 0.22722, dev f1 score = 0.92486, Time 186m 1s (- 79m 43s)
Epoch 15/20: training loss = 0.07332, dev loss = 0.22683, dev f1 score = 0.93017, Time 199m 8s (- 66m 22s)
Epoch 16/20: training loss = 0.07344, dev loss = 0.24556, dev f1 score = 0.93448, Time 212m 16s (- 53m 4s)
Epoch 17/20: training loss = 0.06488, dev loss = 0.21160, dev f1 score = 0.93791, Time 225m 22s (- 39m 46s)
Update best f1: 0.93567 -> 0.93791, thres 0.40, saving model to f1_retry.pth
Epoch 18/20: training loss = 0.05854, dev loss = 0.23763, dev f1 score = 0.93430, Time 238m 38s (- 26m 30s)
Epoch 19/20: training loss = 0.06286, dev loss = 0.23557, dev f1 score = 0.92575, Time 251m 44s (- 13m 14s)
Epoch 20/20: training loss = 0.05375, dev loss = 0.28304, dev f1 score = 0.92566, Time 264m 49s (- 0m 0s)
Best dev f1: 0.93791 Best dev loss: 0.19300
